"""
AgentScope å¤šæ™ºèƒ½ä½“åä½œæ¨¡å—

å®ç°ä¸‰ä¸ªåä½œ Agentï¼š
1. StructurizerAgent - å°†ç”¨æˆ·éç»“æ„åŒ–è¾“å…¥è½¬ä¸ºç»“æ„åŒ–æ•°æ®
2. WriterAgent - æ ¹æ®ç»“æ„åŒ–æ•°æ®åˆ›ä½œæ–‡æ¡£
3. ReviewerAgent - å¯¹æ–‡æ¡£è¯„åˆ†å¹¶å†³å®šæ˜¯å¦é‡æ–°ç”Ÿæˆ

å·¥ä½œæµç¨‹ï¼š
ç”¨æˆ·è¾“å…¥ â†’ ç»“æ„åŒ–Agent â†’ åˆ›ä½œAgent â†’ è¯„åˆ†Agent â†’ [è¯„åˆ†>=7] â†’ è¾“å‡º
                                        â†“ [è¯„åˆ†<7]
                                      é‡æ–°åˆ›ä½œï¼ˆæœ€å¤š3è½®ï¼‰
"""

import json
from typing import Optional, Dict, Any, List, Tuple
from dataclasses import dataclass, field
from abc import ABC, abstractmethod

# AgentScope å¯¼å…¥ï¼ˆå¦‚æœå·²å®‰è£…ï¼‰
try:
    import agentscope
    from agentscope.agents import AgentBase, ReActAgent
    from agentscope.message import Msg
    from agentscope.pipelines import SequentialPipeline
    AGENTSCOPE_AVAILABLE = True
except ImportError:
    AGENTSCOPE_AVAILABLE = False
    print("AgentScope æœªå®‰è£…ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿå®ç°")


# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class StructuredTask:
    """ç»“æ„åŒ–ä»»åŠ¡æ•°æ®"""
    intent: str  # æ„å›¾ï¼šcreate, update, format ç­‰
    document_name: Optional[str] = None
    title: Optional[str] = None
    content_requirements: List[str] = field(default_factory=list)
    style_requirements: Dict[str, Any] = field(default_factory=dict)
    include_table: bool = False
    table_data: Optional[List[List[str]]] = None
    include_image: bool = False
    image_query: Optional[str] = None
    additional_notes: str = ""
    
    def to_dict(self) -> dict:
        return {
            "intent": self.intent,
            "document_name": self.document_name,
            "title": self.title,
            "content_requirements": self.content_requirements,
            "style_requirements": self.style_requirements,
            "include_table": self.include_table,
            "table_data": self.table_data,
            "include_image": self.include_image,
            "image_query": self.image_query,
            "additional_notes": self.additional_notes
        }


@dataclass
class DocumentDraft:
    """æ–‡æ¡£è‰ç¨¿"""
    filename: str
    title: str
    content: str
    tables: List[List[List[str]]] = field(default_factory=list)
    images: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass 
class ReviewResult:
    """è¯„å®¡ç»“æœ"""
    score: int  # 1-10
    passed: bool  # score >= threshold
    feedback: str
    improvement_suggestions: List[str] = field(default_factory=list)
    strengths: List[str] = field(default_factory=list)


@dataclass
class CoTThinking:
    """Chain of Thought æ€è€ƒè¿‡ç¨‹"""
    # æ€»ç»“åˆ†æ
    task_summary: str  # åŸå§‹ä»»åŠ¡æ€»ç»“
    draft_summary: str  # æ–‡æ¡£è‰ç¨¿æ€»ç»“
    
    # å…³ç³»å˜åŒ–åˆ†æ
    requirement_coverage: Dict[str, bool] = field(default_factory=dict)  # éœ€æ±‚è¦†ç›–æƒ…å†µ
    intent_alignment: str = ""  # æ„å›¾å¯¹é½ç¨‹åº¦åˆ†æ
    style_consistency: str = ""  # é£æ ¼ä¸€è‡´æ€§åˆ†æ
    
    # æŒ‡ä»¤ä¸€è‡´æ€§åˆ†æ
    instruction_analysis: str = ""  # æŒ‡ä»¤æ‰§è¡Œåˆ†æ
    deviation_points: List[str] = field(default_factory=list)  # åç¦»ç‚¹
    alignment_score: float = 0.0  # å¯¹é½å¾—åˆ† (0-1)
    
    # æ·±åº¦æ€è€ƒ
    reasoning_chain: List[str] = field(default_factory=list)  # æ¨ç†é“¾æ¡
    key_observations: List[str] = field(default_factory=list)  # å…³é”®è§‚å¯Ÿ
    
    def to_dict(self) -> dict:
        return {
            "task_summary": self.task_summary,
            "draft_summary": self.draft_summary,
            "requirement_coverage": self.requirement_coverage,
            "intent_alignment": self.intent_alignment,
            "style_consistency": self.style_consistency,
            "instruction_analysis": self.instruction_analysis,
            "deviation_points": self.deviation_points,
            "alignment_score": self.alignment_score,
            "reasoning_chain": self.reasoning_chain,
            "key_observations": self.key_observations
        }


@dataclass
class DimensionScore:
    """å¤šç»´åº¦è¯„åˆ†"""
    content_quality: float = 0.0  # å†…å®¹è´¨é‡ (1-10)
    structure_organization: float = 0.0  # ç»“æ„ç»„ç»‡ (1-10)
    language_expression: float = 0.0  # è¯­è¨€è¡¨è¾¾ (1-10)
    format_standard: float = 0.0  # æ ¼å¼è§„èŒƒ (1-10)
    requirement_match: float = 0.0  # éœ€æ±‚åŒ¹é…åº¦ (1-10)
    
    # å„ç»´åº¦æƒé‡
    weights: Dict[str, float] = field(default_factory=lambda: {
        "content_quality": 0.30,
        "structure_organization": 0.20,
        "language_expression": 0.20,
        "format_standard": 0.10,
        "requirement_match": 0.20
    })
    
    # å„ç»´åº¦è¯¦ç»†è¯„ä»·
    dimension_feedback: Dict[str, str] = field(default_factory=dict)
    
    def calculate_weighted_score(self) -> float:
        """è®¡ç®—åŠ æƒæ€»åˆ†"""
        total = (
            self.content_quality * self.weights["content_quality"] +
            self.structure_organization * self.weights["structure_organization"] +
            self.language_expression * self.weights["language_expression"] +
            self.format_standard * self.weights["format_standard"] +
            self.requirement_match * self.weights["requirement_match"]
        )
        return round(total, 2)
    
    def to_dict(self) -> dict:
        return {
            "content_quality": self.content_quality,
            "structure_organization": self.structure_organization,
            "language_expression": self.language_expression,
            "format_standard": self.format_standard,
            "requirement_match": self.requirement_match,
            "weighted_total": self.calculate_weighted_score(),
            "dimension_feedback": self.dimension_feedback
        }


@dataclass
class AgentFeedback:
    """å‘é€ç»™å…¶ä»– Agent çš„åé¦ˆ"""
    target_agent: str  # ç›®æ ‡ Agent: "structurizer" | "writer"
    priority: str  # ä¼˜å…ˆçº§: "high" | "medium" | "low"
    feedback_type: str  # åé¦ˆç±»å‹: "improvement" | "warning" | "suggestion"
    message: str  # åé¦ˆå†…å®¹
    specific_points: List[str] = field(default_factory=list)  # å…·ä½“è¦ç‚¹
    action_items: List[str] = field(default_factory=list)  # å»ºè®®è¡ŒåŠ¨
    context: Dict[str, Any] = field(default_factory=dict)  # ä¸Šä¸‹æ–‡ä¿¡æ¯
    
    def to_dict(self) -> dict:
        return {
            "target_agent": self.target_agent,
            "priority": self.priority,
            "feedback_type": self.feedback_type,
            "message": self.message,
            "specific_points": self.specific_points,
            "action_items": self.action_items,
            "context": self.context
        }


@dataclass
class EnhancedReviewResult:
    """å¢å¼ºç‰ˆè¯„å®¡ç»“æœ"""
    # åŸºç¡€è¯„å®¡ä¿¡æ¯
    score: int  # æœ€ç»ˆè¯„åˆ† 1-10
    passed: bool  # æ˜¯å¦é€šè¿‡
    
    # CoT æ€è€ƒè¿‡ç¨‹
    cot_thinking: CoTThinking = None
    
    # å¤šç»´åº¦è¯„åˆ†
    dimension_scores: DimensionScore = None
    
    # ç»¼åˆåé¦ˆ
    overall_feedback: str = ""
    strengths: List[str] = field(default_factory=list)
    weaknesses: List[str] = field(default_factory=list)
    improvement_suggestions: List[str] = field(default_factory=list)
    
    # ç»™å…¶ä»– Agent çš„åé¦ˆ
    agent_feedbacks: List[AgentFeedback] = field(default_factory=list)
    
    # å…ƒä¿¡æ¯
    review_timestamp: str = ""
    review_iteration: int = 0
    
    def to_dict(self) -> dict:
        return {
            "score": self.score,
            "passed": self.passed,
            "cot_thinking": self.cot_thinking.to_dict() if self.cot_thinking else None,
            "dimension_scores": self.dimension_scores.to_dict() if self.dimension_scores else None,
            "overall_feedback": self.overall_feedback,
            "strengths": self.strengths,
            "weaknesses": self.weaknesses,
            "improvement_suggestions": self.improvement_suggestions,
            "agent_feedbacks": [f.to_dict() for f in self.agent_feedbacks],
            "review_timestamp": self.review_timestamp,
            "review_iteration": self.review_iteration
        }
    
    def get_feedback_for_agent(self, agent_name: str) -> List[AgentFeedback]:
        """è·å–å‘é€ç»™ç‰¹å®š Agent çš„åé¦ˆ"""
        return [f for f in self.agent_feedbacks if f.target_agent == agent_name]


# ==================== Agent åŸºç±»ï¼ˆæœ¬åœ°å®ç°ï¼‰====================

class BaseAgent(ABC):
    """Agent åŸºç±»"""
    
    def __init__(self, name: str, system_prompt: str, model_config: Optional[Dict] = None):
        self.name = name
        self.system_prompt = system_prompt
        self.model_config = model_config or {}
        self.history: List[Dict] = []
    
    @abstractmethod
    def process(self, input_data: Any) -> Any:
        """å¤„ç†è¾“å…¥ï¼Œè¿”å›è¾“å‡º"""
        pass
    
    def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨ LLMï¼ˆéœ€è¦å®ç°å…·ä½“çš„ API è°ƒç”¨ï¼‰"""
        # è¿™é‡Œå¯ä»¥æ¥å…¥ OpenAIã€Geminiã€æœ¬åœ°æ¨¡å‹ç­‰
        # è¿”å›æ¨¡æ‹Ÿç»“æœç”¨äºæ¼”ç¤º
        return f"[{self.name}] å¤„ç†å®Œæˆ"


# ==================== ç»“æ„åŒ– Agent ====================

class StructurizerAgent(BaseAgent):
    """
    ç»“æ„åŒ– Agentï¼šå°†ç”¨æˆ·éç»“æ„åŒ–è¾“å…¥è½¬ä¸ºç»“æ„åŒ–ä»»åŠ¡æ•°æ®
    
    èŒè´£ï¼š
    - è¯†åˆ«ç”¨æˆ·æ„å›¾ï¼ˆåˆ›å»º/ä¿®æ”¹/åˆ é™¤æ–‡æ¡£ç­‰ï¼‰
    - æå–å…³é”®å‚æ•°ï¼ˆæ–‡ä»¶åã€æ ‡é¢˜ã€å†…å®¹è¦æ±‚ï¼‰
    - è¯†åˆ«ç‰¹æ®Šéœ€æ±‚ï¼ˆè¡¨æ ¼ã€å›¾ç‰‡ã€æ ¼å¼è¦æ±‚ï¼‰
    - æ ‡è®°ç¼ºå¤±ä¿¡æ¯ï¼Œç”Ÿæˆæ¾„æ¸…é—®é¢˜
    """
    
    def __init__(self, model_config: Optional[Dict] = None):
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªè¾“å…¥ç»“æ„åŒ–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„éç»“æ„åŒ–è¯·æ±‚è½¬æ¢ä¸ºç»“æ„åŒ–çš„ä»»åŠ¡æ•°æ®ã€‚

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
{
    "intent": "create|update|delete|format|add_table|insert_image|search",
    "document_name": "æ–‡ä»¶åæˆ–null",
    "title": "æ–‡æ¡£æ ‡é¢˜æˆ–null", 
    "content_requirements": ["å†…å®¹è¦æ±‚1", "å†…å®¹è¦æ±‚2"],
    "style_requirements": {"tone": "æ­£å¼/è½»æ¾", "length": "çŸ­/ä¸­/é•¿"},
    "include_table": true/false,
    "table_data": [[è¡¨æ ¼æ•°æ®]] æˆ– null,
    "include_image": true/false,
    "image_query": "å›¾ç‰‡æœç´¢å…³é”®è¯æˆ–null",
    "additional_notes": "å…¶ä»–å¤‡æ³¨",
    "missing_info": ["ç¼ºå¤±çš„ä¿¡æ¯"],
    "clarification_questions": ["éœ€è¦å‘ç”¨æˆ·ç¡®è®¤çš„é—®é¢˜"]
}

## è§„åˆ™
1. ä¸è¦å‡è®¾ä»»ä½•æœªæ˜ç¡®æä¾›çš„ä¿¡æ¯
2. ç¼ºå¤±å…³é”®ä¿¡æ¯æ—¶ï¼Œåœ¨ missing_info ä¸­åˆ—å‡º
3. æœ‰æ­§ä¹‰æ—¶ï¼Œåœ¨ clarification_questions ä¸­æé—®
4. åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–è§£é‡Š"""
        
        super().__init__("Structurizer", system_prompt, model_config)
    
    def process(self, user_input: str) -> Tuple[StructuredTask, List[str]]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œè¿”å›ç»“æ„åŒ–ä»»åŠ¡å’Œéœ€è¦æ¾„æ¸…çš„é—®é¢˜
        
        Args:
            user_input: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¾“å…¥
            
        Returns:
            (StructuredTask, clarification_questions)
        """
        # æ„å»º prompt
        prompt = f"{self.system_prompt}\n\nç”¨æˆ·è¾“å…¥ï¼š{user_input}"
        
        # è°ƒç”¨ LLM æˆ–ä½¿ç”¨è§„åˆ™è§£æ
        result = self._parse_input(user_input)
        
        return result
    
    def _parse_input(self, text: str) -> Tuple[StructuredTask, List[str]]:
        """ä½¿ç”¨è§„åˆ™è§£æè¾“å…¥ï¼ˆå¯æ›¿æ¢ä¸º LLM è°ƒç”¨ï¼‰"""
        import re
        
        task = StructuredTask(intent="create")
        questions = []
        
        # è¯†åˆ«æ„å›¾
        text_lower = text.lower()
        if any(kw in text_lower for kw in ["åˆ›å»º", "æ–°å»º", "ç”Ÿæˆ", "å†™", "create"]):
            task.intent = "create"
        elif any(kw in text_lower for kw in ["ä¿®æ”¹", "æ›´æ–°", "è¿½åŠ ", "update"]):
            task.intent = "update"
        elif any(kw in text_lower for kw in ["åˆ é™¤", "ç§»é™¤", "delete"]):
            task.intent = "delete"
        elif any(kw in text_lower for kw in ["æ ¼å¼", "åŠ ç²—", "format"]):
            task.intent = "format"
        
        # æå–æ–‡ä»¶å
        match = re.search(r'[\w\u4e00-\u9fff_-]+\.docx', text)
        if match:
            task.document_name = match.group()
        else:
            match = re.search(r'(?:æ–‡æ¡£|æ–‡ä»¶|å«|åä¸º|å‘½å)\s*[ï¼š:]*\s*["\']?([^"\'ï¼Œã€‚\s]+)', text)
            if match:
                task.document_name = match.group(1)
            else:
                questions.append("è¯·é—®æ–‡æ¡£è¦å«ä»€ä¹ˆåå­—ï¼Ÿ")
        
        # æå–æ ‡é¢˜
        match = re.search(r'æ ‡é¢˜[ï¼š:ä¸ºæ˜¯]\s*["\']?([^"\'ï¼Œã€‚\n]+)', text)
        if match:
            task.title = match.group(1).strip()
        
        # æ£€æµ‹è¡¨æ ¼éœ€æ±‚
        if any(kw in text for kw in ["è¡¨æ ¼", "table", "åˆ—è¡¨"]):
            task.include_table = True
            questions.append("è¯·æä¾›è¡¨æ ¼çš„å…·ä½“æ•°æ®å†…å®¹")
        
        # æ£€æµ‹å›¾ç‰‡éœ€æ±‚
        if any(kw in text for kw in ["å›¾ç‰‡", "å›¾åƒ", "image", "picture"]):
            task.include_image = True
            match = re.search(r'(?:å…³äº|æœ‰å…³|å±•ç¤º)\s*([^çš„]+)\s*çš„?\s*å›¾', text)
            if match:
                task.image_query = match.group(1)
            else:
                questions.append("è¯·é—®éœ€è¦ä»€ä¹ˆä¸»é¢˜çš„å›¾ç‰‡ï¼Ÿ")
        
        # æå–å†…å®¹è¦æ±‚
        content_patterns = [
            r'å†…å®¹[ï¼š:åŒ…å«åŒ…æ‹¬æœ‰]\s*(.+?)(?:[ã€‚ï¼›]|$)',
            r'å†™[ï¼š:]\s*(.+?)(?:[ã€‚ï¼›]|$)',
            r'ä»‹ç»\s*(.+?)(?:[ã€‚ï¼›]|$)',
        ]
        for pattern in content_patterns:
            match = re.search(pattern, text)
            if match:
                task.content_requirements.append(match.group(1).strip())
        
        # æ£€æµ‹é£æ ¼è¦æ±‚
        if any(kw in text for kw in ["æ­£å¼", "ä¸“ä¸š", "å•†åŠ¡"]):
            task.style_requirements["tone"] = "formal"
        elif any(kw in text for kw in ["è½»æ¾", "æ´»æ³¼", "æœ‰è¶£"]):
            task.style_requirements["tone"] = "casual"
        
        if any(kw in text for kw in ["ç®€çŸ­", "ç®€æ´", "brief"]):
            task.style_requirements["length"] = "short"
        elif any(kw in text for kw in ["è¯¦ç»†", "å®Œæ•´", "è¯¦å°½"]):
            task.style_requirements["length"] = "long"
        
        return task, questions


# ==================== åˆ›ä½œ Agent ====================

class WriterAgent(BaseAgent):
    """
    åˆ›ä½œ Agentï¼šæ ¹æ®ç»“æ„åŒ–ä»»åŠ¡åˆ›ä½œæ–‡æ¡£å†…å®¹
    
    èŒè´£ï¼š
    - æ ¹æ®å†…å®¹è¦æ±‚ç”Ÿæˆæ–‡æ¡£æ­£æ–‡
    - æ ¹æ®é£æ ¼è¦æ±‚è°ƒæ•´å†™ä½œé£æ ¼
    - ç”Ÿæˆè¡¨æ ¼æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
    - è°ƒç”¨å·¥å…·å®Œæˆæ–‡æ¡£æ“ä½œ
    """
    
    def __init__(self, word_tools: Dict = None, model_config: Optional[Dict] = None):
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£æ’°å†™ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç»“æ„åŒ–çš„ä»»åŠ¡è¦æ±‚åˆ›ä½œé«˜è´¨é‡çš„æ–‡æ¡£å†…å®¹ã€‚

## å†™ä½œåŸåˆ™
1. å†…å®¹è¦åˆ‡é¢˜ã€å‡†ç¡®ã€æœ‰ä»·å€¼
2. ç»“æ„æ¸…æ™°ï¼Œæ®µè½åˆ†æ˜
3. è¯­è¨€æµç•…ï¼Œç¬¦åˆæŒ‡å®šçš„é£æ ¼è¦æ±‚
4. é€‚å½“ä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ç­‰æ ¼å¼å¢å¼ºå¯è¯»æ€§

## è¾“å‡ºè¦æ±‚
ç›´æ¥è¾“å‡ºæ–‡æ¡£å†…å®¹ï¼Œä½¿ç”¨ Markdown æ ¼å¼æ ‡è®°æ ‡é¢˜å’Œåˆ—è¡¨ã€‚"""
        
        super().__init__("Writer", system_prompt, model_config)
        self.word_tools = word_tools or {}
    
    def process(self, task: StructuredTask) -> DocumentDraft:
        """
        æ ¹æ®ç»“æ„åŒ–ä»»åŠ¡åˆ›ä½œæ–‡æ¡£
        
        Args:
            task: ç»“æ„åŒ–ä»»åŠ¡æ•°æ®
            
        Returns:
            DocumentDraft æ–‡æ¡£è‰ç¨¿
        """
        # ç”Ÿæˆæ–‡æ¡£å†…å®¹
        content = self._generate_content(task)
        
        # åˆ›å»ºè‰ç¨¿
        draft = DocumentDraft(
            filename=task.document_name or f"document_{self._timestamp()}.docx",
            title=task.title or "æœªå‘½åæ–‡æ¡£",
            content=content,
            metadata={
                "intent": task.intent,
                "style": task.style_requirements
            }
        )
        
        # å¦‚æœéœ€è¦è¡¨æ ¼
        if task.include_table and task.table_data:
            draft.tables.append(task.table_data)
        
        return draft
    
    def _generate_content(self, task: StructuredTask) -> str:
        """ç”Ÿæˆæ–‡æ¡£å†…å®¹ï¼ˆå¯æ›¿æ¢ä¸º LLM è°ƒç”¨ï¼‰"""
        # è¿™é‡Œæ˜¯æ¨¡æ¿ç”Ÿæˆï¼Œå®é™…ä½¿ç”¨æ—¶åº”è°ƒç”¨ LLM
        content_parts = []
        
        if task.title:
            content_parts.append(f"# {task.title}\n")
        
        if task.content_requirements:
            content_parts.append("## ä¸»è¦å†…å®¹\n")
            for req in task.content_requirements:
                content_parts.append(f"{req}\n")
        
        if task.additional_notes:
            content_parts.append(f"\n{task.additional_notes}\n")
        
        return "\n".join(content_parts) if content_parts else "æ–‡æ¡£å†…å®¹å¾…è¡¥å……"
    
    def _timestamp(self) -> str:
        from datetime import datetime
        return datetime.now().strftime("%Y%m%d_%H%M%S")


# ==================== è¯„å®¡ Agent ====================

class ReviewerAgent(BaseAgent):
    """
    è¯„å®¡ Agentï¼šå¯¹æ–‡æ¡£è¿›è¡Œè¯„åˆ†å¹¶æä¾›åé¦ˆ
    
    èŒè´£ï¼š
    - è¯„ä¼°æ–‡æ¡£è´¨é‡ï¼ˆå†…å®¹ã€ç»“æ„ã€è¯­è¨€ï¼‰
    - ç»™å‡º 1-10 åˆ†çš„è¯„åˆ†
    - æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®
    - å†³å®šæ˜¯å¦éœ€è¦é‡æ–°ç”Ÿæˆ
    """
    
    def __init__(self, pass_threshold: int = 7, model_config: Optional[Dict] = None):
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„æ–‡æ¡£è¯„å®¡ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯„ä¼°æ–‡æ¡£è´¨é‡å¹¶æä¾›å»ºè®¾æ€§åé¦ˆã€‚

## è¯„åˆ†ç»´åº¦ï¼ˆæ¯é¡¹ 1-10 åˆ†ï¼‰
1. å†…å®¹è´¨é‡ï¼šä¿¡æ¯å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€ä»·å€¼
2. ç»“æ„ç»„ç»‡ï¼šé€»è¾‘æ€§ã€å±‚æ¬¡æ„Ÿã€å¯è¯»æ€§
3. è¯­è¨€è¡¨è¾¾ï¼šæµç•…åº¦ã€ä¸“ä¸šæ€§ã€é£æ ¼ä¸€è‡´æ€§
4. æ ¼å¼è§„èŒƒï¼šæ ‡é¢˜ã€æ®µè½ã€åˆ—è¡¨ä½¿ç”¨

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
{
    "scores": {
        "content": 8,
        "structure": 7,
        "language": 8,
        "format": 7
    },
    "overall_score": 7.5,
    "strengths": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
    "weaknesses": ["ä¸è¶³1", "ä¸è¶³2"],
    "suggestions": ["å»ºè®®1", "å»ºè®®2"],
    "verdict": "pass" æˆ– "revise"
}"""
        
        super().__init__("Reviewer", system_prompt, model_config)
        self.pass_threshold = pass_threshold
        self.review_history: List[EnhancedReviewResult] = []  # è¯„å®¡å†å²
    
    def process(self, draft: DocumentDraft, task: StructuredTask) -> ReviewResult:
        """
        è¯„å®¡æ–‡æ¡£è‰ç¨¿ï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
        
        Args:
            draft: æ–‡æ¡£è‰ç¨¿
            task: åŸå§‹ä»»åŠ¡ï¼ˆç”¨äºå¯¹æ¯”æ£€æŸ¥ï¼‰
            
        Returns:
            ReviewResult è¯„å®¡ç»“æœ
        """
        # è¯„ä¼°æ–‡æ¡£
        score, feedback, suggestions, strengths = self._evaluate(draft, task)
        
        return ReviewResult(
            score=score,
            passed=score >= self.pass_threshold,
            feedback=feedback,
            improvement_suggestions=suggestions,
            strengths=strengths
        )
    
    def process_enhanced(
        self, 
        draft: DocumentDraft, 
        task: StructuredTask,
        iteration: int = 1,
        previous_review: Optional['EnhancedReviewResult'] = None
    ) -> EnhancedReviewResult:
        """
        å¢å¼ºç‰ˆè¯„å®¡å¤„ç† - åŒ…å« CoT æ€è€ƒã€å¤šç»´åº¦è¯„åˆ†å’Œ Agent åé¦ˆ
        
        Args:
            draft: æ–‡æ¡£è‰ç¨¿
            task: åŸå§‹ä»»åŠ¡
            iteration: å½“å‰è¯„å®¡è½®æ¬¡
            previous_review: ä¸Šä¸€è½®è¯„å®¡ç»“æœï¼ˆç”¨äºå¯¹æ¯”åˆ†æï¼‰
            
        Returns:
            EnhancedReviewResult å¢å¼ºç‰ˆè¯„å®¡ç»“æœ
        """
        from datetime import datetime
        
        # Step 1: CoT æ€è€ƒè¿‡ç¨‹
        print("    ğŸ§  å¼€å§‹ Chain of Thought æ€è€ƒ...")
        cot = self._perform_cot_thinking(draft, task, previous_review)
        
        # Step 2: å¤šç»´åº¦è¯„åˆ†
        print("    ğŸ“Š è¿›è¡Œå¤šç»´åº¦è¯„åˆ†...")
        dimension_scores = self._calculate_dimension_scores(draft, task, cot)
        
        # Step 3: ç”Ÿæˆç»¼åˆè¯„ä»·
        print("    ğŸ“ ç”Ÿæˆç»¼åˆè¯„ä»·...")
        strengths, weaknesses, suggestions = self._generate_comprehensive_feedback(
            draft, task, cot, dimension_scores
        )
        
        # Step 4: è®¡ç®—æœ€ç»ˆå¾—åˆ†
        final_score = int(round(dimension_scores.calculate_weighted_score()))
        final_score = max(1, min(10, final_score))
        
        # Step 5: ç”Ÿæˆç»™å…¶ä»– Agent çš„åé¦ˆ
        print("    ğŸ’¬ ç”Ÿæˆ Agent åé¦ˆ...")
        agent_feedbacks = self._generate_agent_feedbacks(
            draft, task, cot, dimension_scores, strengths, weaknesses, suggestions
        )
        
        # æ„å»ºå¢å¼ºç‰ˆè¯„å®¡ç»“æœ
        result = EnhancedReviewResult(
            score=final_score,
            passed=final_score >= self.pass_threshold,
            cot_thinking=cot,
            dimension_scores=dimension_scores,
            overall_feedback=self._generate_overall_feedback(final_score, cot),
            strengths=strengths,
            weaknesses=weaknesses,
            improvement_suggestions=suggestions,
            agent_feedbacks=agent_feedbacks,
            review_timestamp=datetime.now().isoformat(),
            review_iteration=iteration
        )
        
        # ä¿å­˜åˆ°è¯„å®¡å†å²
        self.review_history.append(result)
        
        return result
    
    def _perform_cot_thinking(
        self, 
        draft: DocumentDraft, 
        task: StructuredTask,
        previous_review: Optional['EnhancedReviewResult'] = None
    ) -> CoTThinking:
        """
        æ‰§è¡Œ Chain of Thought æ€è€ƒè¿‡ç¨‹
        
        åŒ…æ‹¬ï¼š
        1. ä»»åŠ¡å’Œè‰ç¨¿æ€»ç»“
        2. éœ€æ±‚è¦†ç›–åˆ†æ
        3. æ„å›¾å’Œé£æ ¼ä¸€è‡´æ€§æ£€æŸ¥
        4. æŒ‡ä»¤å¯¹é½åˆ†æ
        """
        reasoning_chain = []
        key_observations = []
        
        # === 1. ä»»åŠ¡æ€»ç»“ ===
        reasoning_chain.append("ğŸ“‹ åˆ†æåŸå§‹ä»»åŠ¡è¦æ±‚...")
        task_summary = f"æ„å›¾ï¼š{task.intent}ï¼Œç›®æ ‡æ–‡æ¡£ï¼š{task.document_name or 'æœªæŒ‡å®š'}ï¼Œæ ‡é¢˜è¦æ±‚ï¼š{task.title or 'æœªæŒ‡å®š'}"
        if task.content_requirements:
            task_summary += f"ï¼Œå†…å®¹è¦æ±‚ï¼š{len(task.content_requirements)}é¡¹"
        if task.style_requirements:
            task_summary += f"ï¼Œé£æ ¼è¦æ±‚ï¼š{task.style_requirements}"
        
        reasoning_chain.append(f"  â†’ ä»»åŠ¡è§£æå®Œæˆï¼š{task_summary[:100]}...")
        
        # === 2. è‰ç¨¿æ€»ç»“ ===
        reasoning_chain.append("ğŸ“„ åˆ†ææ–‡æ¡£è‰ç¨¿...")
        content_length = len(draft.content)
        has_structure = "##" in draft.content or "\n\n" in draft.content
        has_lists = "- " in draft.content or "* " in draft.content or "1. " in draft.content
        
        draft_summary = f"æ ‡é¢˜ï¼š{draft.title}ï¼Œå†…å®¹é•¿åº¦ï¼š{content_length}å­—ç¬¦"
        if has_structure:
            draft_summary += "ï¼Œæœ‰å±‚æ¬¡ç»“æ„"
        if has_lists:
            draft_summary += "ï¼ŒåŒ…å«åˆ—è¡¨"
        if draft.tables:
            draft_summary += f"ï¼Œ{len(draft.tables)}ä¸ªè¡¨æ ¼"
        if draft.images:
            draft_summary += f"ï¼Œ{len(draft.images)}å¼ å›¾ç‰‡"
        
        reasoning_chain.append(f"  â†’ è‰ç¨¿è§£æå®Œæˆï¼š{draft_summary}")
        
        # === 3. éœ€æ±‚è¦†ç›–åˆ†æ ===
        reasoning_chain.append("ğŸ” æ£€æŸ¥éœ€æ±‚è¦†ç›–æƒ…å†µ...")
        requirement_coverage = {}
        coverage_issues = []
        
        for i, req in enumerate(task.content_requirements):
            # ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„è¯­ä¹‰åŒ¹é…ï¼‰
            req_keywords = [w for w in req.split() if len(w) > 2]
            matched = any(kw.lower() in draft.content.lower() for kw in req_keywords) if req_keywords else (req.lower() in draft.content.lower())
            requirement_coverage[f"éœ€æ±‚{i+1}: {req[:30]}..."] = matched
            
            if matched:
                key_observations.append(f"âœ“ éœ€æ±‚ '{req[:20]}...' å·²è¦†ç›–")
            else:
                coverage_issues.append(f"éœ€æ±‚ '{req[:20]}...' æœªå……åˆ†è¦†ç›–")
                key_observations.append(f"âœ— éœ€æ±‚ '{req[:20]}...' æœªè¦†ç›–")
        
        coverage_rate = sum(requirement_coverage.values()) / len(requirement_coverage) if requirement_coverage else 1.0
        reasoning_chain.append(f"  â†’ éœ€æ±‚è¦†ç›–ç‡ï¼š{coverage_rate*100:.1f}%")
        
        # === 4. æ„å›¾å¯¹é½åˆ†æ ===
        reasoning_chain.append("ğŸ¯ åˆ†ææ„å›¾å¯¹é½ç¨‹åº¦...")
        intent_alignment = ""
        
        if task.intent == "create":
            if draft.content and len(draft.content) > 50:
                intent_alignment = "æ„å›¾å¯¹é½ï¼šå·²æˆåŠŸåˆ›å»ºæ–‡æ¡£å†…å®¹"
            else:
                intent_alignment = "æ„å›¾åå·®ï¼šæ–‡æ¡£åˆ›å»ºä¸å®Œæ•´ï¼Œå†…å®¹è¿‡å°‘"
                key_observations.append("âš ï¸ æ–‡æ¡£å†…å®¹ä¸å¤Ÿå……å®")
        elif task.intent == "update":
            intent_alignment = "æ„å›¾åˆ†æï¼šæ›´æ–°æ“ä½œéœ€éªŒè¯æ”¹åŠ¨æœ‰æ•ˆæ€§"
        elif task.intent == "format":
            intent_alignment = "æ„å›¾åˆ†æï¼šæ ¼å¼åŒ–æ“ä½œéœ€æ£€æŸ¥æ ·å¼å˜åŒ–"
        else:
            intent_alignment = f"æ„å›¾åˆ†æï¼š{task.intent} æ“ä½œå¾…éªŒè¯"
        
        reasoning_chain.append(f"  â†’ {intent_alignment}")
        
        # === 5. é£æ ¼ä¸€è‡´æ€§æ£€æŸ¥ ===
        reasoning_chain.append("ğŸ¨ æ£€æŸ¥é£æ ¼ä¸€è‡´æ€§...")
        style_consistency = ""
        
        required_tone = task.style_requirements.get("tone", "")
        required_length = task.style_requirements.get("length", "")
        
        style_issues = []
        if required_tone == "formal":
            informal_markers = ["å“ˆå“ˆ", "å˜¿å˜¿", "å‘¢", "å•¦", "å“¦", "å‘€"]
            has_informal = any(m in draft.content for m in informal_markers)
            if has_informal:
                style_issues.append("å‘ç°éæ­£å¼è¯­æ°”è¯æ±‡")
            else:
                key_observations.append("âœ“ è¯­æ°”ç¬¦åˆæ­£å¼è¦æ±‚")
        elif required_tone == "casual":
            key_observations.append("âœ“ é‡‡ç”¨è½»æ¾è¯­æ°”")
        
        if required_length == "short" and content_length > 800:
            style_issues.append("å†…å®¹å¯èƒ½è¿‡é•¿ï¼Œè¦æ±‚ç®€çŸ­")
        elif required_length == "long" and content_length < 300:
            style_issues.append("å†…å®¹å¯èƒ½è¿‡çŸ­ï¼Œè¦æ±‚è¯¦ç»†")
        
        if style_issues:
            style_consistency = f"é£æ ¼åå·®ï¼š{'; '.join(style_issues)}"
            key_observations.extend([f"âš ï¸ {issue}" for issue in style_issues])
        else:
            style_consistency = "é£æ ¼ä¸€è‡´ï¼šç¬¦åˆè¦æ±‚çš„é£æ ¼è§„èŒƒ"
        
        reasoning_chain.append(f"  â†’ {style_consistency}")
        
        # === 6. æŒ‡ä»¤ä¸€è‡´æ€§åˆ†æ ===
        reasoning_chain.append("ğŸ“ åˆ†ææŒ‡ä»¤æ‰§è¡Œä¸€è‡´æ€§...")
        deviation_points = []
        alignment_checks = []
        
        # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦ç¬¦åˆè¦æ±‚
        if task.title:
            if task.title.lower() in draft.title.lower() or draft.title.lower() in task.title.lower():
                alignment_checks.append(True)
            else:
                deviation_points.append(f"æ ‡é¢˜ä¸åŒ¹é…ï¼šæœŸæœ›'{task.title}'ï¼Œå®é™…'{draft.title}'")
                alignment_checks.append(False)
        
        # æ£€æŸ¥è¡¨æ ¼éœ€æ±‚
        if task.include_table:
            if draft.tables:
                alignment_checks.append(True)
                key_observations.append("âœ“ å·²åŒ…å«è¡¨æ ¼")
            else:
                deviation_points.append("è¦æ±‚åŒ…å«è¡¨æ ¼ä½†æœªç”Ÿæˆ")
                alignment_checks.append(False)
        
        # æ£€æŸ¥å›¾ç‰‡éœ€æ±‚
        if task.include_image:
            if draft.images:
                alignment_checks.append(True)
                key_observations.append("âœ“ å·²åŒ…å«å›¾ç‰‡")
            else:
                deviation_points.append("è¦æ±‚åŒ…å«å›¾ç‰‡ä½†æœªç”Ÿæˆ")
                alignment_checks.append(False)
        
        # è®¡ç®—å¯¹é½å¾—åˆ†
        alignment_score = sum(alignment_checks) / len(alignment_checks) if alignment_checks else 1.0
        alignment_score = max(0.0, min(1.0, alignment_score))
        
        # è€ƒè™‘éœ€æ±‚è¦†ç›–ç‡
        alignment_score = (alignment_score + coverage_rate) / 2
        
        instruction_analysis = f"æŒ‡ä»¤æ‰§è¡Œåˆ†æï¼šå¯¹é½å¾—åˆ† {alignment_score*100:.1f}%"
        if deviation_points:
            instruction_analysis += f"ï¼Œå‘ç° {len(deviation_points)} ä¸ªåç¦»ç‚¹"
        else:
            instruction_analysis += "ï¼ŒæŒ‡ä»¤æ‰§è¡Œè‰¯å¥½"
        
        reasoning_chain.append(f"  â†’ {instruction_analysis}")
        
        # === 7. ä¸ä¸Šä¸€è½®å¯¹æ¯”ï¼ˆå¦‚æœæœ‰ï¼‰===
        if previous_review:
            reasoning_chain.append("ğŸ“ˆ ä¸ä¸Šä¸€è½®è¯„å®¡å¯¹æ¯”...")
            prev_score = previous_review.score
            if previous_review.improvement_suggestions:
                addressed = sum(1 for s in previous_review.improvement_suggestions 
                               if any(kw in draft.content.lower() for kw in s.lower().split()[:3]))
                reasoning_chain.append(f"  â†’ ä¸Šè½®å»ºè®®é‡‡çº³ï¼š{addressed}/{len(previous_review.improvement_suggestions)}é¡¹")
                key_observations.append(f"ğŸ“ˆ ç›¸æ¯”ä¸Šè½®ï¼Œå·²æ”¹è¿› {addressed} é¡¹å»ºè®®")
        
        reasoning_chain.append("âœ… CoT æ€è€ƒå®Œæˆ")
        
        return CoTThinking(
            task_summary=task_summary,
            draft_summary=draft_summary,
            requirement_coverage=requirement_coverage,
            intent_alignment=intent_alignment,
            style_consistency=style_consistency,
            instruction_analysis=instruction_analysis,
            deviation_points=deviation_points,
            alignment_score=alignment_score,
            reasoning_chain=reasoning_chain,
            key_observations=key_observations
        )
    
    def _calculate_dimension_scores(
        self, 
        draft: DocumentDraft, 
        task: StructuredTask,
        cot: CoTThinking
    ) -> DimensionScore:
        """
        è®¡ç®—å¤šç»´åº¦è¯„åˆ†
        """
        scores = DimensionScore()
        
        # === 1. å†…å®¹è´¨é‡è¯„åˆ† ===
        content_score = 5.0
        content_feedback = []
        
        # å†…å®¹é•¿åº¦
        content_length = len(draft.content)
        if content_length > 1000:
            content_score += 2.0
            content_feedback.append("å†…å®¹å……å®è¯¦å°½")
        elif content_length > 500:
            content_score += 1.5
            content_feedback.append("å†…å®¹è¾ƒä¸ºä¸°å¯Œ")
        elif content_length > 200:
            content_score += 0.5
            content_feedback.append("å†…å®¹åŸºæœ¬è¶³å¤Ÿ")
        else:
            content_score -= 1.0
            content_feedback.append("å†…å®¹è¿‡äºç®€çŸ­")
        
        # éœ€æ±‚è¦†ç›–
        coverage_rate = sum(cot.requirement_coverage.values()) / len(cot.requirement_coverage) if cot.requirement_coverage else 1.0
        content_score += coverage_rate * 2
        content_feedback.append(f"éœ€æ±‚è¦†ç›–ç‡ {coverage_rate*100:.0f}%")
        
        scores.content_quality = max(1.0, min(10.0, content_score))
        scores.dimension_feedback["content_quality"] = "ï¼›".join(content_feedback)
        
        # === 2. ç»“æ„ç»„ç»‡è¯„åˆ† ===
        structure_score = 5.0
        structure_feedback = []
        
        # æ ‡é¢˜å±‚æ¬¡
        h1_count = draft.content.count("# ")
        h2_count = draft.content.count("## ")
        h3_count = draft.content.count("### ")
        
        if h2_count > 0:
            structure_score += 1.5
            structure_feedback.append(f"æœ‰ {h2_count} ä¸ªäºŒçº§æ ‡é¢˜")
        if h3_count > 0:
            structure_score += 1.0
            structure_feedback.append(f"æœ‰ {h3_count} ä¸ªä¸‰çº§æ ‡é¢˜")
        
        # æ®µè½åˆ†å¸ƒ
        paragraphs = [p for p in draft.content.split("\n\n") if p.strip()]
        if len(paragraphs) > 5:
            structure_score += 1.5
            structure_feedback.append("æ®µè½åˆ’åˆ†åˆç†")
        elif len(paragraphs) > 2:
            structure_score += 0.5
            structure_feedback.append("æœ‰åŸºæœ¬æ®µè½ç»“æ„")
        else:
            structure_feedback.append("æ®µè½è¾ƒå°‘ï¼Œå»ºè®®åˆ†æ®µ")
        
        # åˆ—è¡¨ä½¿ç”¨
        has_lists = "- " in draft.content or "* " in draft.content or "1. " in draft.content
        if has_lists:
            structure_score += 1.0
            structure_feedback.append("åˆç†ä½¿ç”¨åˆ—è¡¨")
        
        scores.structure_organization = max(1.0, min(10.0, structure_score))
        scores.dimension_feedback["structure_organization"] = "ï¼›".join(structure_feedback)
        
        # === 3. è¯­è¨€è¡¨è¾¾è¯„åˆ† ===
        language_score = 6.0  # åŸºç¡€å‡è®¾è¯­è¨€å¯æ¥å—
        language_feedback = []
        
        # å¥å­é•¿åº¦åˆ†å¸ƒï¼ˆç®€å•è¯„ä¼°ï¼‰
        sentences = [s for s in draft.content.replace("ã€‚", ".").replace("ï¼", ".").replace("ï¼Ÿ", ".").split(".") if s.strip()]
        if sentences:
            avg_length = sum(len(s) for s in sentences) / len(sentences)
            if 20 < avg_length < 80:
                language_score += 1.5
                language_feedback.append("å¥å­é•¿åº¦é€‚ä¸­")
            elif avg_length > 100:
                language_score -= 0.5
                language_feedback.append("éƒ¨åˆ†å¥å­è¿‡é•¿")
        
        # é£æ ¼ç¬¦åˆåº¦
        if "é£æ ¼åå·®" not in cot.style_consistency:
            language_score += 2.0
            language_feedback.append("é£æ ¼ç¬¦åˆè¦æ±‚")
        else:
            language_score -= 1.0
            language_feedback.append("é£æ ¼æœ‰å¾…è°ƒæ•´")
        
        scores.language_expression = max(1.0, min(10.0, language_score))
        scores.dimension_feedback["language_expression"] = "ï¼›".join(language_feedback)
        
        # === 4. æ ¼å¼è§„èŒƒè¯„åˆ† ===
        format_score = 6.0
        format_feedback = []
        
        # æ ‡é¢˜ä½¿ç”¨
        if draft.title and draft.title != "æœªå‘½åæ–‡æ¡£":
            format_score += 1.5
            format_feedback.append("æœ‰æ˜ç¡®ä¸»æ ‡é¢˜")
        else:
            format_score -= 1.0
            format_feedback.append("ç¼ºå°‘æ˜ç¡®æ ‡é¢˜")
        
        # æ ¼å¼å…ƒç´ 
        if "**" in draft.content or "__" in draft.content:
            format_score += 0.5
            format_feedback.append("ä½¿ç”¨äº†å¼ºè°ƒæ ¼å¼")
        
        if draft.tables:
            format_score += 1.0
            format_feedback.append("åŒ…å«è¡¨æ ¼")
        elif task.include_table:
            format_score -= 1.0
            format_feedback.append("ç¼ºå°‘è¦æ±‚çš„è¡¨æ ¼")
        
        if draft.images:
            format_score += 1.0
            format_feedback.append("åŒ…å«å›¾ç‰‡")
        elif task.include_image:
            format_score -= 1.0
            format_feedback.append("ç¼ºå°‘è¦æ±‚çš„å›¾ç‰‡")
        
        scores.format_standard = max(1.0, min(10.0, format_score))
        scores.dimension_feedback["format_standard"] = "ï¼›".join(format_feedback)
        
        # === 5. éœ€æ±‚åŒ¹é…åº¦è¯„åˆ† ===
        match_score = 5.0 + cot.alignment_score * 5
        match_feedback = [f"æŒ‡ä»¤å¯¹é½åº¦ {cot.alignment_score*100:.0f}%"]
        
        if not cot.deviation_points:
            match_feedback.append("æ— æ˜æ˜¾åç¦»")
        else:
            match_feedback.append(f"å­˜åœ¨ {len(cot.deviation_points)} ä¸ªåç¦»ç‚¹")
        
        scores.requirement_match = max(1.0, min(10.0, match_score))
        scores.dimension_feedback["requirement_match"] = "ï¼›".join(match_feedback)
        
        return scores
    
    def _generate_comprehensive_feedback(
        self,
        draft: DocumentDraft,
        task: StructuredTask,
        cot: CoTThinking,
        scores: DimensionScore
    ) -> Tuple[List[str], List[str], List[str]]:
        """
        ç”Ÿæˆç»¼åˆåé¦ˆï¼šä¼˜ç‚¹ã€ä¸è¶³å’Œæ”¹è¿›å»ºè®®
        """
        strengths = []
        weaknesses = []
        suggestions = []
        
        # åŸºäºç»´åº¦è¯„åˆ†ç”Ÿæˆåé¦ˆ
        if scores.content_quality >= 7:
            strengths.append(f"å†…å®¹è´¨é‡ä¼˜ç§€ï¼ˆ{scores.content_quality:.1f}åˆ†ï¼‰")
        elif scores.content_quality < 5:
            weaknesses.append(f"å†…å®¹è´¨é‡ä¸è¶³ï¼ˆ{scores.content_quality:.1f}åˆ†ï¼‰")
            suggestions.append("ä¸°å¯Œæ–‡æ¡£å†…å®¹ï¼Œå¢åŠ æ›´å¤šæœ‰ä»·å€¼çš„ä¿¡æ¯")
        
        if scores.structure_organization >= 7:
            strengths.append(f"ç»“æ„ç»„ç»‡æ¸…æ™°ï¼ˆ{scores.structure_organization:.1f}åˆ†ï¼‰")
        elif scores.structure_organization < 5:
            weaknesses.append(f"ç»“æ„ç»„ç»‡æ¬ ä½³ï¼ˆ{scores.structure_organization:.1f}åˆ†ï¼‰")
            suggestions.append("æ·»åŠ å°æ ‡é¢˜å’Œæ®µè½åˆ†éš”ï¼Œæ”¹å–„æ–‡æ¡£ç»“æ„")
        
        if scores.language_expression >= 7:
            strengths.append(f"è¯­è¨€è¡¨è¾¾æµç•…ï¼ˆ{scores.language_expression:.1f}åˆ†ï¼‰")
        elif scores.language_expression < 5:
            weaknesses.append(f"è¯­è¨€è¡¨è¾¾éœ€æ”¹è¿›ï¼ˆ{scores.language_expression:.1f}åˆ†ï¼‰")
            suggestions.append("è°ƒæ•´è¯­è¨€é£æ ¼ï¼Œä½¿è¡¨è¾¾æ›´åŠ æµç•…è‡ªç„¶")
        
        if scores.format_standard >= 7:
            strengths.append(f"æ ¼å¼è§„èŒƒè‰¯å¥½ï¼ˆ{scores.format_standard:.1f}åˆ†ï¼‰")
        elif scores.format_standard < 5:
            weaknesses.append(f"æ ¼å¼è§„èŒƒä¸è¶³ï¼ˆ{scores.format_standard:.1f}åˆ†ï¼‰")
            suggestions.append("è§„èŒƒæ–‡æ¡£æ ¼å¼ï¼Œæ­£ç¡®ä½¿ç”¨æ ‡é¢˜å’Œåˆ—è¡¨")
        
        if scores.requirement_match >= 7:
            strengths.append(f"éœ€æ±‚åŒ¹é…åº¦é«˜ï¼ˆ{scores.requirement_match:.1f}åˆ†ï¼‰")
        elif scores.requirement_match < 5:
            weaknesses.append(f"éœ€æ±‚åŒ¹é…ä¸è¶³ï¼ˆ{scores.requirement_match:.1f}åˆ†ï¼‰")
            suggestions.append("ä»”ç»†æ£€æŸ¥åŸå§‹éœ€æ±‚ï¼Œç¡®ä¿æ‰€æœ‰è¦ç‚¹éƒ½å·²è¦†ç›–")
        
        # åŸºäº CoT åˆ†ææ·»åŠ å…·ä½“åé¦ˆ
        for obs in cot.key_observations:
            if obs.startswith("âœ“"):
                strengths.append(obs[2:].strip())
            elif obs.startswith("âœ—") or obs.startswith("âš ï¸"):
                weaknesses.append(obs[2:].strip())
        
        # åŸºäºåç¦»ç‚¹ç”Ÿæˆå»ºè®®
        for deviation in cot.deviation_points:
            suggestions.append(f"ä¿®æ­£ï¼š{deviation}")
        
        # å»é‡
        strengths = list(dict.fromkeys(strengths))
        weaknesses = list(dict.fromkeys(weaknesses))
        suggestions = list(dict.fromkeys(suggestions))
        
        return strengths, weaknesses, suggestions
    
    def _generate_overall_feedback(self, score: int, cot: CoTThinking) -> str:
        """ç”Ÿæˆæ€»ä½“åé¦ˆ"""
        if score >= 8:
            verdict = "ä¼˜ç§€"
            comment = "æ–‡æ¡£è´¨é‡å‡ºè‰²ï¼Œæ»¡è¶³å„é¡¹è¦æ±‚ã€‚"
        elif score >= 7:
            verdict = "è‰¯å¥½"
            comment = "æ–‡æ¡£è´¨é‡è¾¾æ ‡ï¼Œå¯ä»¥ä½¿ç”¨ã€‚"
        elif score >= 5:
            verdict = "ä¸€èˆ¬"
            comment = "æ–‡æ¡£æœ‰æ”¹è¿›ç©ºé—´ï¼Œå»ºè®®æ ¹æ®åé¦ˆä¿®æ”¹ã€‚"
        else:
            verdict = "éœ€æ”¹è¿›"
            comment = "æ–‡æ¡£éœ€è¦è¾ƒå¤§æ”¹è¿›ï¼Œè¯·å‚è€ƒå…·ä½“å»ºè®®ã€‚"
        
        feedback = f"ã€{verdict}ã€‘è¯„åˆ†ï¼š{score}/10ã€‚{comment}"
        feedback += f" æŒ‡ä»¤å¯¹é½åº¦ï¼š{cot.alignment_score*100:.0f}%ã€‚"
        
        if cot.deviation_points:
            feedback += f" å‘ç° {len(cot.deviation_points)} ä¸ªåç¦»ç‚¹éœ€è¦å¤„ç†ã€‚"
        
        return feedback
    
    def _generate_agent_feedbacks(
        self,
        draft: DocumentDraft,
        task: StructuredTask,
        cot: CoTThinking,
        scores: DimensionScore,
        strengths: List[str],
        weaknesses: List[str],
        suggestions: List[str]
    ) -> List[AgentFeedback]:
        """
        ç”Ÿæˆå‘é€ç»™å…¶ä»– Agent çš„ä¸“é¡¹åé¦ˆ
        """
        feedbacks = []
        
        # === ç»™ WriterAgentï¼ˆåˆ›ä½œAgentï¼‰çš„åé¦ˆ ===
        writer_specific_points = []
        writer_action_items = []
        writer_priority = "medium"
        
        # å†…å®¹ç›¸å…³åé¦ˆ
        if scores.content_quality < 6:
            writer_priority = "high"
            writer_specific_points.append("å†…å®¹æ·±åº¦ä¸å¤Ÿï¼Œéœ€è¦æ‰©å……")
            writer_action_items.append("å¢åŠ å…·ä½“æ¡ˆä¾‹ã€æ•°æ®æˆ–è¯¦ç»†è¯´æ˜")
        
        if scores.structure_organization < 6:
            writer_specific_points.append("æ–‡æ¡£ç»“æ„éœ€è¦ä¼˜åŒ–")
            writer_action_items.append("ä½¿ç”¨å¤šçº§æ ‡é¢˜ç»„ç»‡å†…å®¹")
            writer_action_items.append("ç¡®ä¿æ®µè½ä¹‹é—´æœ‰é€»è¾‘è¿‡æ¸¡")
        
        if scores.language_expression < 6:
            writer_specific_points.append("è¯­è¨€è¡¨è¾¾éœ€è¦æ”¹è¿›")
            if task.style_requirements.get("tone") == "formal":
                writer_action_items.append("ä½¿ç”¨æ›´ä¸“ä¸šã€æ­£å¼çš„è¯­è¨€")
            else:
                writer_action_items.append("ä½¿è¯­è¨€æ›´åŠ é€šä¿—æ˜“æ‡‚")
        
        # åŸºäºåç¦»ç‚¹ç”Ÿæˆåé¦ˆ
        for deviation in cot.deviation_points:
            if "è¡¨æ ¼" in deviation:
                writer_specific_points.append("ç¼ºå°‘å¿…è¦çš„è¡¨æ ¼")
                writer_action_items.append("æ ¹æ®éœ€æ±‚ç”Ÿæˆæ•°æ®è¡¨æ ¼")
            elif "å›¾ç‰‡" in deviation:
                writer_specific_points.append("ç¼ºå°‘å¿…è¦çš„å›¾ç‰‡")
                writer_action_items.append("æ·»åŠ ç›¸å…³é…å›¾")
            elif "æ ‡é¢˜" in deviation:
                writer_specific_points.append("æ ‡é¢˜ä¸ç¬¦åˆè¦æ±‚")
                writer_action_items.append(f"å°†æ ‡é¢˜ä¿®æ”¹ä¸ºï¼š{task.title}")
        
        # éœ€æ±‚è¦†ç›–åé¦ˆ
        uncovered = [k for k, v in cot.requirement_coverage.items() if not v]
        if uncovered:
            writer_priority = "high"
            writer_specific_points.append(f"æœ‰ {len(uncovered)} é¡¹éœ€æ±‚æœªè¦†ç›–")
            for uc in uncovered[:3]:  # æœ€å¤šåˆ—å‡º3é¡¹
                writer_action_items.append(f"è¡¥å……å†…å®¹ï¼š{uc}")
        
        writer_feedback_msg = "åŸºäºæ–‡æ¡£è¯„å®¡ï¼Œåˆ›ä½œAgentéœ€è¦å…³æ³¨ä»¥ä¸‹æ–¹é¢ä»¥æå‡æ–‡æ¡£è´¨é‡ã€‚"
        if not writer_specific_points:
            writer_feedback_msg = "æ–‡æ¡£åˆ›ä½œè´¨é‡è‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰é£æ ¼å’Œæ·±åº¦ã€‚"
            writer_priority = "low"
        
        feedbacks.append(AgentFeedback(
            target_agent="writer",
            priority=writer_priority,
            feedback_type="improvement" if writer_specific_points else "suggestion",
            message=writer_feedback_msg,
            specific_points=writer_specific_points,
            action_items=writer_action_items,
            context={
                "current_score": scores.calculate_weighted_score(),
                "content_score": scores.content_quality,
                "structure_score": scores.structure_organization,
                "language_score": scores.language_expression,
                "iteration": getattr(self, '_current_iteration', 1)
            }
        ))
        
        # === ç»™ StructurizerAgentï¼ˆç»“æ„åŒ–Agentï¼‰çš„åé¦ˆ ===
        structurizer_specific_points = []
        structurizer_action_items = []
        structurizer_priority = "low"
        
        # åˆ†æä»»åŠ¡ç»“æ„åŒ–çš„é—®é¢˜
        if not task.content_requirements:
            structurizer_priority = "high"
            structurizer_specific_points.append("å†…å®¹è¦æ±‚æå–ä¸å®Œæ•´")
            structurizer_action_items.append("æ›´ç»†è‡´åœ°è§£æç”¨æˆ·æ„å›¾ï¼Œæå–å…·ä½“çš„å†…å®¹è¦æ±‚")
        
        if not task.title and cot.alignment_score < 0.7:
            structurizer_specific_points.append("æ ‡é¢˜ä¿¡æ¯ç¼ºå¤±")
            structurizer_action_items.append("å°è¯•ä»ç”¨æˆ·è¾“å…¥æ¨æ–­æˆ–è¯¢é—®æ ‡é¢˜")
        
        if task.include_table and not task.table_data:
            structurizer_specific_points.append("è¡¨æ ¼éœ€æ±‚è¯†åˆ«ä½†æ•°æ®æœªæå–")
            structurizer_action_items.append("åœ¨è¯†åˆ«è¡¨æ ¼éœ€æ±‚æ—¶ï¼Œå°è¯•æå–æˆ–è¯¢é—®å…·ä½“æ•°æ®")
        
        # é£æ ¼è¦æ±‚åˆ†æ
        if not task.style_requirements:
            structurizer_specific_points.append("é£æ ¼è¦æ±‚æœªæ˜ç¡®")
            structurizer_action_items.append("è¯†åˆ«ç”¨æˆ·å¯¹è¯­æ°”ã€é•¿åº¦ç­‰é£æ ¼çš„éšå«è¦æ±‚")
        
        # æ„å›¾ç›¸å…³åé¦ˆ
        if "åå·®" in cot.intent_alignment:
            structurizer_priority = "medium"
            structurizer_specific_points.append("æ„å›¾è¯†åˆ«å¯èƒ½å­˜åœ¨åå·®")
            structurizer_action_items.append("é‡æ–°å®¡è§†ç”¨æˆ·è¾“å…¥ï¼Œç¡®è®¤çœŸå®æ„å›¾")
        
        structurizer_feedback_msg = "åŸºäºæ–‡æ¡£ç”Ÿæˆç»“æœï¼Œç»“æ„åŒ–Agentçš„è§£æå¯ä»¥åœ¨ä»¥ä¸‹æ–¹é¢ä¼˜åŒ–ã€‚"
        if not structurizer_specific_points:
            structurizer_feedback_msg = "ä»»åŠ¡ç»“æ„åŒ–è´¨é‡è‰¯å¥½ï¼Œéœ€æ±‚è§£æå‡†ç¡®å®Œæ•´ã€‚"
            structurizer_priority = "low"
        else:
            structurizer_priority = max(structurizer_priority, "medium")
        
        feedbacks.append(AgentFeedback(
            target_agent="structurizer",
            priority=structurizer_priority,
            feedback_type="improvement" if structurizer_specific_points else "suggestion",
            message=structurizer_feedback_msg,
            specific_points=structurizer_specific_points,
            action_items=structurizer_action_items,
            context={
                "task_completeness": len([v for v in [task.title, task.document_name, task.content_requirements] if v]) / 3,
                "requirement_coverage": cot.alignment_score,
                "original_task": task.to_dict()
            }
        ))
        
        return feedbacks
    
    def get_feedback_summary(self) -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰è¯„å®¡å†å²çš„åé¦ˆæ±‡æ€»
        """
        if not self.review_history:
            return {"message": "æš‚æ— è¯„å®¡å†å²"}
        
        all_writer_feedback = []
        all_structurizer_feedback = []
        score_trend = []
        
        for review in self.review_history:
            score_trend.append(review.score)
            for fb in review.agent_feedbacks:
                if fb.target_agent == "writer":
                    all_writer_feedback.append(fb.to_dict())
                elif fb.target_agent == "structurizer":
                    all_structurizer_feedback.append(fb.to_dict())
        
        return {
            "total_reviews": len(self.review_history),
            "score_trend": score_trend,
            "average_score": sum(score_trend) / len(score_trend),
            "latest_score": score_trend[-1],
            "writer_feedback_count": len(all_writer_feedback),
            "structurizer_feedback_count": len(all_structurizer_feedback),
            "latest_writer_feedback": all_writer_feedback[-1] if all_writer_feedback else None,
            "latest_structurizer_feedback": all_structurizer_feedback[-1] if all_structurizer_feedback else None
        }
    
    def _evaluate(self, draft: DocumentDraft, task: StructuredTask) -> Tuple[int, str, List[str], List[str]]:
        """è¯„ä¼°æ–‡æ¡£ï¼ˆå¯æ›¿æ¢ä¸º LLM è°ƒç”¨ï¼‰"""
        suggestions = []
        strengths = []
        score = 5  # åŸºç¡€åˆ†
        
        # æ£€æŸ¥æ ‡é¢˜
        if draft.title and draft.title != "æœªå‘½åæ–‡æ¡£":
            score += 1
            strengths.append("æœ‰æ˜ç¡®çš„æ ‡é¢˜")
        else:
            suggestions.append("æ·»åŠ ä¸€ä¸ªæœ‰æ„ä¹‰çš„æ ‡é¢˜")
        
        # æ£€æŸ¥å†…å®¹é•¿åº¦
        content_length = len(draft.content)
        if content_length > 500:
            score += 2
            strengths.append("å†…å®¹å……å®")
        elif content_length > 200:
            score += 1
        else:
            suggestions.append("å†…å®¹è¾ƒçŸ­ï¼Œå»ºè®®æ‰©å……æ›´å¤šç»†èŠ‚")
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³ä»»åŠ¡è¦æ±‚
        for req in task.content_requirements:
            if req.lower() in draft.content.lower():
                score += 0.5
                strengths.append(f"è¦†ç›–äº†è¦æ±‚ï¼š{req[:20]}...")
            else:
                suggestions.append(f"æœªå®Œå…¨è¦†ç›–è¦æ±‚ï¼š{req[:20]}...")
        
        # æ£€æŸ¥ç»“æ„
        if "##" in draft.content or "\n\n" in draft.content:
            score += 1
            strengths.append("æœ‰è‰¯å¥½çš„æ®µè½ç»“æ„")
        else:
            suggestions.append("å»ºè®®æ·»åŠ å°æ ‡é¢˜æˆ–åˆ†æ®µ")
        
        # é™åˆ¶åˆ†æ•°èŒƒå›´
        score = max(1, min(10, int(score)))
        
        feedback = f"æ–‡æ¡£è¯„åˆ†ï¼š{score}/10ã€‚" 
        if score >= self.pass_threshold:
            feedback += "æ–‡æ¡£è´¨é‡è¾¾æ ‡ï¼Œå¯ä»¥ä½¿ç”¨ã€‚"
        else:
            feedback += f"æ–‡æ¡£éœ€è¦æ”¹è¿›ï¼Œç›®æ ‡åˆ†æ•°ï¼š{self.pass_threshold}ã€‚"
        
        return score, feedback, suggestions, strengths


# ==================== åä½œ Pipeline ====================

class DocumentCreationPipeline:
    """
    æ–‡æ¡£åˆ›å»º Pipelineï¼šåè°ƒä¸‰ä¸ª Agent å®Œæˆæ–‡æ¡£åˆ›å»ºä»»åŠ¡
    
    æµç¨‹ï¼š
    1. ç”¨æˆ·è¾“å…¥ â†’ StructurizerAgent â†’ ç»“æ„åŒ–ä»»åŠ¡
    2. ç»“æ„åŒ–ä»»åŠ¡ â†’ WriterAgent â†’ æ–‡æ¡£è‰ç¨¿
    3. æ–‡æ¡£è‰ç¨¿ â†’ ReviewerAgent â†’ è¯„å®¡ç»“æœï¼ˆå« CoT æ€è€ƒå’Œ Agent åé¦ˆï¼‰
    4. å¦‚æœè¯„åˆ†ä¸è¾¾æ ‡ï¼Œæ ¹æ®åé¦ˆè¿”å›æ­¥éª¤2é‡æ–°åˆ›ä½œï¼ˆæœ€å¤š max_iterations è½®ï¼‰
    5. ç”Ÿæˆæœ€ç»ˆåé¦ˆæŠ¥å‘Šç»™æ‰€æœ‰ Agent
    """
    
    def __init__(
        self,
        word_tools: Dict = None,
        pass_threshold: int = 7,
        max_iterations: int = 3,
        model_config: Optional[Dict] = None,
        enable_enhanced_review: bool = True  # æ˜¯å¦å¯ç”¨å¢å¼ºè¯„å®¡
    ):
        self.structurizer = StructurizerAgent(model_config)
        self.writer = WriterAgent(word_tools, model_config)
        self.reviewer = ReviewerAgent(pass_threshold, model_config)
        self.max_iterations = max_iterations
        self.word_tools = word_tools or {}
        self.enable_enhanced_review = enable_enhanced_review
        
        # åé¦ˆæ”¶é›†å™¨
        self.feedback_history: List[Dict[str, Any]] = []
    
    def run(self, user_input: str, auto_confirm: bool = False) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„æ–‡æ¡£åˆ›å»ºæµç¨‹
        
        Args:
            user_input: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¾“å…¥
            auto_confirm: æ˜¯å¦è‡ªåŠ¨ç¡®è®¤ï¼ˆè·³è¿‡æ¾„æ¸…é—®é¢˜ï¼‰
            
        Returns:
            åŒ…å«æœ€ç»ˆç»“æœçš„å­—å…¸
        """
        result = {
            "success": False,
            "iterations": 0,
            "stages": [],
            "agent_feedbacks": []  # æ–°å¢ï¼šæ”¶é›†æ‰€æœ‰ Agent åé¦ˆ
        }
        
        # é˜¶æ®µ1ï¼šç»“æ„åŒ–
        print(f"\n{'='*60}")
        print("ğŸ” é˜¶æ®µ1ï¼šç»“æ„åŒ–ç”¨æˆ·è¾“å…¥")
        print(f"{'='*60}")
        
        task, questions = self.structurizer.process(user_input)
        
        result["stages"].append({
            "stage": "structurize",
            "task": task.to_dict(),
            "clarification_questions": questions
        })
        
        print(f"âœ… è¯†åˆ«æ„å›¾ï¼š{task.intent}")
        print(f"ğŸ“„ æ–‡æ¡£åï¼š{task.document_name or 'å¾…ç¡®å®š'}")
        print(f"ğŸ“Œ æ ‡é¢˜ï¼š{task.title or 'å¾…ç¡®å®š'}")
        if task.content_requirements:
            print(f"ğŸ“‹ å†…å®¹è¦æ±‚ï¼š{len(task.content_requirements)} é¡¹")
        if task.style_requirements:
            print(f"ğŸ¨ é£æ ¼è¦æ±‚ï¼š{task.style_requirements}")
        
        if questions and not auto_confirm:
            print(f"\nâš ï¸ éœ€è¦æ¾„æ¸…çš„é—®é¢˜ï¼š")
            for q in questions:
                print(f"   - {q}")
            result["needs_clarification"] = True
            result["questions"] = questions
            return result
        
        # é˜¶æ®µ2-3ï¼šåˆ›ä½œå’Œè¯„å®¡å¾ªç¯
        iteration = 0
        draft = None
        review = None
        enhanced_review = None
        previous_enhanced_review = None
        
        while iteration < self.max_iterations:
            iteration += 1
            result["iterations"] = iteration
            
            # é˜¶æ®µ2ï¼šåˆ›ä½œ
            print(f"\n{'='*60}")
            print(f"âœï¸ é˜¶æ®µ2ï¼šåˆ›ä½œæ–‡æ¡£ (ç¬¬ {iteration} è½®)")
            print(f"{'='*60}")
            
            # å¦‚æœæœ‰ä¸Šä¸€è½®çš„åé¦ˆï¼ŒåŠ å…¥ä»»åŠ¡
            if enhanced_review and not enhanced_review.passed:
                # ä½¿ç”¨å¢å¼ºç‰ˆåé¦ˆ
                writer_feedbacks = enhanced_review.get_feedback_for_agent("writer")
                if writer_feedbacks:
                    improvement_notes = []
                    for fb in writer_feedbacks:
                        improvement_notes.extend(fb.action_items)
                    task.additional_notes = f"æ”¹è¿›å»ºè®®ï¼š{'; '.join(improvement_notes)}"
                    print(f"ğŸ“¨ æ”¶åˆ°æ¥è‡ª Reviewer çš„åé¦ˆï¼š{len(improvement_notes)} é¡¹æ”¹è¿›å»ºè®®")
            elif review and not review.passed:
                # å…¼å®¹åŸºç¡€ç‰ˆåé¦ˆ
                task.additional_notes = f"æ”¹è¿›å»ºè®®ï¼š{'; '.join(review.improvement_suggestions)}"
            
            draft = self.writer.process(task)
            
            result["stages"].append({
                "stage": f"write_iteration_{iteration}",
                "draft": {
                    "filename": draft.filename,
                    "title": draft.title,
                    "content_preview": draft.content[:200] + "..." if len(draft.content) > 200 else draft.content
                }
            })
            
            print(f"âœ… ç”Ÿæˆæ–‡æ¡£ï¼š{draft.filename}")
            print(f"ğŸ“ å†…å®¹é•¿åº¦ï¼š{len(draft.content)} å­—ç¬¦")
            
            # é˜¶æ®µ3ï¼šè¯„å®¡ï¼ˆå¢å¼ºç‰ˆï¼‰
            print(f"\n{'='*60}")
            print(f"â­ é˜¶æ®µ3ï¼š{'å¢å¼ºç‰ˆ' if self.enable_enhanced_review else ''}è¯„å®¡æ–‡æ¡£ (ç¬¬ {iteration} è½®)")
            print(f"{'='*60}")
            
            if self.enable_enhanced_review:
                # ä½¿ç”¨å¢å¼ºç‰ˆè¯„å®¡
                enhanced_review = self.reviewer.process_enhanced(
                    draft, 
                    task, 
                    iteration=iteration,
                    previous_review=previous_enhanced_review
                )
                
                # æ‰“å° CoT æ€è€ƒè¿‡ç¨‹
                print(f"\n  ğŸ§  Chain of Thought æ€è€ƒè¿‡ç¨‹ï¼š")
                for step in enhanced_review.cot_thinking.reasoning_chain:
                    print(f"    {step}")
                
                # æ‰“å°å…³é”®è§‚å¯Ÿ
                if enhanced_review.cot_thinking.key_observations:
                    print(f"\n  ğŸ” å…³é”®è§‚å¯Ÿï¼š")
                    for obs in enhanced_review.cot_thinking.key_observations[:5]:
                        print(f"    {obs}")
                
                # æ‰“å°å¤šç»´åº¦è¯„åˆ†
                print(f"\n  ğŸ“Š å¤šç»´åº¦è¯„åˆ†ï¼š")
                scores = enhanced_review.dimension_scores
                print(f"    â€¢ å†…å®¹è´¨é‡ï¼š{scores.content_quality:.1f}/10 - {scores.dimension_feedback.get('content_quality', '')}")
                print(f"    â€¢ ç»“æ„ç»„ç»‡ï¼š{scores.structure_organization:.1f}/10 - {scores.dimension_feedback.get('structure_organization', '')}")
                print(f"    â€¢ è¯­è¨€è¡¨è¾¾ï¼š{scores.language_expression:.1f}/10 - {scores.dimension_feedback.get('language_expression', '')}")
                print(f"    â€¢ æ ¼å¼è§„èŒƒï¼š{scores.format_standard:.1f}/10 - {scores.dimension_feedback.get('format_standard', '')}")
                print(f"    â€¢ éœ€æ±‚åŒ¹é…ï¼š{scores.requirement_match:.1f}/10 - {scores.dimension_feedback.get('requirement_match', '')}")
                print(f"    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
                print(f"    ğŸ“ˆ åŠ æƒæ€»åˆ†ï¼š{scores.calculate_weighted_score():.2f}/10")
                
                # æ‰“å°æ€»ä½“åé¦ˆ
                print(f"\n  ğŸ’¬ æ€»ä½“è¯„ä»·ï¼š{enhanced_review.overall_feedback}")
                
                # æ‰“å°ä¼˜ç¼ºç‚¹
                if enhanced_review.strengths:
                    print(f"\n  ğŸ’ª ä¼˜ç‚¹ï¼š")
                    for s in enhanced_review.strengths[:5]:
                        print(f"    âœ“ {s}")
                
                if enhanced_review.weaknesses:
                    print(f"\n  âš ï¸ ä¸è¶³ï¼š")
                    for w in enhanced_review.weaknesses[:5]:
                        print(f"    âœ— {w}")
                
                if enhanced_review.improvement_suggestions:
                    print(f"\n  ğŸ’¡ æ”¹è¿›å»ºè®®ï¼š")
                    for s in enhanced_review.improvement_suggestions[:5]:
                        print(f"    â†’ {s}")
                
                # æ‰“å° Agent åé¦ˆ
                print(f"\n  ğŸ“¨ å‘é€ç»™å…¶ä»– Agent çš„åé¦ˆï¼š")
                for fb in enhanced_review.agent_feedbacks:
                    priority_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(fb.priority, "âšª")
                    print(f"\n    [{priority_icon} {fb.target_agent.upper()}] {fb.message}")
                    if fb.specific_points:
                        print(f"      è¦ç‚¹ï¼š{', '.join(fb.specific_points[:3])}")
                    if fb.action_items:
                        print(f"      è¡ŒåŠ¨é¡¹ï¼š")
                        for action in fb.action_items[:3]:
                            print(f"        â€¢ {action}")
                
                # ä¿å­˜åé¦ˆå†å²
                self.feedback_history.append({
                    "iteration": iteration,
                    "feedbacks": [fb.to_dict() for fb in enhanced_review.agent_feedbacks]
                })
                
                # æ·»åŠ åˆ°ç»“æœ
                result["stages"].append({
                    "stage": f"enhanced_review_iteration_{iteration}",
                    "review": enhanced_review.to_dict()
                })
                
                # è®°å½• Agent åé¦ˆ
                result["agent_feedbacks"].extend([fb.to_dict() for fb in enhanced_review.agent_feedbacks])
                
                print(f"\n  ğŸ“Š æœ€ç»ˆè¯„åˆ†ï¼š{enhanced_review.score}/10")
                print(f"  {'âœ… é€šè¿‡' if enhanced_review.passed else 'âŒ éœ€æ”¹è¿›'}")
                
                if enhanced_review.passed:
                    break
                
                previous_enhanced_review = enhanced_review
                
            else:
                # ä½¿ç”¨åŸºç¡€ç‰ˆè¯„å®¡
                review = self.reviewer.process(draft, task)
                
                result["stages"].append({
                    "stage": f"review_iteration_{iteration}",
                    "review": {
                        "score": review.score,
                        "passed": review.passed,
                        "feedback": review.feedback,
                        "suggestions": review.improvement_suggestions,
                        "strengths": review.strengths
                    }
                })
                
                print(f"ğŸ“Š è¯„åˆ†ï¼š{review.score}/10")
                print(f"{'âœ… é€šè¿‡' if review.passed else 'âŒ éœ€æ”¹è¿›'}")
                
                if review.strengths:
                    print(f"ğŸ’ª ä¼˜ç‚¹ï¼š{', '.join(review.strengths)}")
                if review.improvement_suggestions:
                    print(f"ğŸ’¡ å»ºè®®ï¼š{', '.join(review.improvement_suggestions)}")
                
                if review.passed:
                    break
            
            if iteration < self.max_iterations:
                print(f"\nğŸ”„ å°†æ ¹æ®åé¦ˆé‡æ–°åˆ›ä½œ...")
        
        # æœ€ç»ˆç»“æœ
        final_review = enhanced_review if self.enable_enhanced_review else review
        result["success"] = final_review.passed if final_review else False
        result["final_draft"] = {
            "filename": draft.filename,
            "title": draft.title,
            "content": draft.content,
            "tables": draft.tables,
            "images": draft.images
        } if draft else None
        
        if self.enable_enhanced_review and enhanced_review:
            result["final_review"] = enhanced_review.to_dict()
        elif review:
            result["final_review"] = {
                "score": review.score,
                "passed": review.passed,
                "feedback": review.feedback
            }
        
        # ç”Ÿæˆæœ€ç»ˆåé¦ˆæ±‡æ€»
        if self.enable_enhanced_review:
            result["feedback_summary"] = self.reviewer.get_feedback_summary()
        
        print(f"\n{'='*60}")
        print(f"ğŸ æµç¨‹å®Œæˆ")
        print(f"{'='*60}")
        print(f"æ€»è½®æ•°ï¼š{iteration}")
        print(f"æœ€ç»ˆè¯„åˆ†ï¼š{final_review.score if final_review else 'N/A'}/10")
        print(f"çŠ¶æ€ï¼š{'âœ… æˆåŠŸ' if result['success'] else 'âŒ æœªè¾¾æ ‡'}")
        
        if self.enable_enhanced_review and self.feedback_history:
            print(f"\nğŸ“‹ åé¦ˆæ±‡æ€»ï¼š")
            summary = self.reviewer.get_feedback_summary()
            print(f"  æ€»è¯„å®¡æ¬¡æ•°ï¼š{summary.get('total_reviews', 0)}")
            print(f"  å¹³å‡è¯„åˆ†ï¼š{summary.get('average_score', 0):.2f}")
            print(f"  è¯„åˆ†è¶‹åŠ¿ï¼š{' â†’ '.join(map(str, summary.get('score_trend', [])))}")
        
        return result
    
    def run_enhanced(self, user_input: str, auto_confirm: bool = False) -> Dict[str, Any]:
        """
        è¿è¡Œå¢å¼ºç‰ˆæµç¨‹ï¼ˆä¾¿æ·æ–¹æ³•ï¼‰
        """
        self.enable_enhanced_review = True
        return self.run(user_input, auto_confirm)
    
    def get_all_agent_feedbacks(self) -> Dict[str, List[Dict]]:
        """
        è·å–æ‰€æœ‰ Agent çš„åé¦ˆæ±‡æ€»
        
        Returns:
            æŒ‰ Agent åˆ†ç±»çš„æ‰€æœ‰åé¦ˆ
        """
        writer_feedbacks = []
        structurizer_feedbacks = []
        
        for history in self.feedback_history:
            for fb in history.get("feedbacks", []):
                if fb["target_agent"] == "writer":
                    writer_feedbacks.append({
                        "iteration": history["iteration"],
                        **fb
                    })
                elif fb["target_agent"] == "structurizer":
                    structurizer_feedbacks.append({
                        "iteration": history["iteration"],
                        **fb
                    })
        
        return {
            "writer": writer_feedbacks,
            "structurizer": structurizer_feedbacks
        }
    
    def generate_improvement_report(self) -> str:
        """
        ç”Ÿæˆæ”¹è¿›å»ºè®®æŠ¥å‘Š
        
        Returns:
            æ ¼å¼åŒ–çš„æ”¹è¿›å»ºè®®æŠ¥å‘Š
        """
        report_lines = [
            "=" * 60,
            "ğŸ“ Agent æ”¹è¿›å»ºè®®æŠ¥å‘Š",
            "=" * 60,
            ""
        ]
        
        all_feedbacks = self.get_all_agent_feedbacks()
        
        # Writer Agent åé¦ˆ
        writer_fbs = all_feedbacks.get("writer", [])
        if writer_fbs:
            report_lines.append("ğŸ–Šï¸ ç»™åˆ›ä½œ Agent (Writer) çš„å»ºè®®ï¼š")
            report_lines.append("-" * 40)
            
            # æ”¶é›†æ‰€æœ‰é«˜ä¼˜å…ˆçº§å»ºè®®
            high_priority = [fb for fb in writer_fbs if fb.get("priority") == "high"]
            if high_priority:
                report_lines.append("\n  ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼š")
                for fb in high_priority:
                    report_lines.append(f"    â€¢ {fb.get('message', '')}")
                    for action in fb.get("action_items", [])[:3]:
                        report_lines.append(f"      â†’ {action}")
            
            # å¸¸è§é—®é¢˜æ¨¡å¼
            all_points = []
            for fb in writer_fbs:
                all_points.extend(fb.get("specific_points", []))
            
            if all_points:
                from collections import Counter
                common_issues = Counter(all_points).most_common(5)
                report_lines.append("\n  ğŸ“Š å¸¸è§é—®é¢˜ï¼š")
                for issue, count in common_issues:
                    report_lines.append(f"    â€¢ [{count}æ¬¡] {issue}")
            
            report_lines.append("")
        
        # Structurizer Agent åé¦ˆ
        struct_fbs = all_feedbacks.get("structurizer", [])
        if struct_fbs:
            report_lines.append("ğŸ” ç»™ç»“æ„åŒ– Agent (Structurizer) çš„å»ºè®®ï¼š")
            report_lines.append("-" * 40)
            
            # æ”¶é›†å»ºè®®
            for fb in struct_fbs:
                if fb.get("specific_points"):
                    report_lines.append(f"\n  ç¬¬ {fb.get('iteration', '?')} è½®åé¦ˆï¼š")
                    for point in fb.get("specific_points", []):
                        report_lines.append(f"    â€¢ {point}")
                    for action in fb.get("action_items", [])[:3]:
                        report_lines.append(f"      â†’ {action}")
            
            report_lines.append("")
        
        # æ€»ç»“
        summary = self.reviewer.get_feedback_summary()
        if summary.get("total_reviews", 0) > 0:
            report_lines.extend([
                "=" * 60,
                "ğŸ“ˆ è¯„å®¡ç»Ÿè®¡",
                "=" * 60,
                f"  â€¢ æ€»è¯„å®¡æ¬¡æ•°ï¼š{summary.get('total_reviews', 0)}",
                f"  â€¢ å¹³å‡è¯„åˆ†ï¼š{summary.get('average_score', 0):.2f}/10",
                f"  â€¢ æœ€ç»ˆè¯„åˆ†ï¼š{summary.get('latest_score', 0)}/10",
                f"  â€¢ è¯„åˆ†è¶‹åŠ¿ï¼š{' â†’ '.join(map(str, summary.get('score_trend', [])))}",
            ])
        
        return "\n".join(report_lines)
    
    def save_document(self, draft: DocumentDraft) -> Dict[str, Any]:
        """
        ä½¿ç”¨ Word å·¥å…·ä¿å­˜æ–‡æ¡£
        
        Args:
            draft: æ–‡æ¡£è‰ç¨¿
            
        Returns:
            ä¿å­˜ç»“æœ
        """
        if "create_document" in self.word_tools:
            return self.word_tools["create_document"](
                filename=draft.filename,
                title=draft.title,
                content=draft.content
            )
        return {"success": False, "error": "create_document å·¥å…·æœªé…ç½®"}


# ==================== AgentScope é›†æˆï¼ˆå¦‚æœå¯ç”¨ï¼‰====================

if AGENTSCOPE_AVAILABLE:
    class AgentScopeStructurizer(AgentBase):
        """AgentScope ç‰ˆæœ¬çš„ç»“æ„åŒ– Agent"""
        
        def __init__(self, name: str = "Structurizer", model_config_name: str = None):
            super().__init__(name=name, model_config_name=model_config_name)
            self.local_agent = StructurizerAgent()
        
        def reply(self, x: Msg) -> Msg:
            task, questions = self.local_agent.process(x.content)
            return Msg(
                name=self.name,
                content=json.dumps({
                    "task": task.to_dict(),
                    "questions": questions
                }, ensure_ascii=False),
                role="assistant"
            )
    
    class AgentScopeWriter(AgentBase):
        """AgentScope ç‰ˆæœ¬çš„åˆ›ä½œ Agent"""
        
        def __init__(self, name: str = "Writer", model_config_name: str = None):
            super().__init__(name=name, model_config_name=model_config_name)
            self.local_agent = WriterAgent()
        
        def reply(self, x: Msg) -> Msg:
            task_data = json.loads(x.content)
            task = StructuredTask(**task_data.get("task", {}))
            draft = self.local_agent.process(task)
            return Msg(
                name=self.name,
                content=json.dumps({
                    "filename": draft.filename,
                    "title": draft.title,
                    "content": draft.content
                }, ensure_ascii=False),
                role="assistant"
            )
    
    class AgentScopeReviewer(AgentBase):
        """AgentScope ç‰ˆæœ¬çš„è¯„å®¡ Agent"""
        
        def __init__(self, name: str = "Reviewer", model_config_name: str = None, pass_threshold: int = 7):
            super().__init__(name=name, model_config_name=model_config_name)
            self.local_agent = ReviewerAgent(pass_threshold)
        
        def reply(self, x: Msg) -> Msg:
            data = json.loads(x.content)
            draft = DocumentDraft(**data.get("draft", {}))
            task = StructuredTask(**data.get("task", {}))
            review = self.local_agent.process(draft, task)
            return Msg(
                name=self.name,
                content=json.dumps({
                    "score": review.score,
                    "passed": review.passed,
                    "feedback": review.feedback,
                    "suggestions": review.improvement_suggestions
                }, ensure_ascii=False),
                role="assistant"
            )


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

def demo():
    """æ¼”ç¤ºå¤š Agent åä½œæµç¨‹"""
    
    # åˆ›å»º Pipelineï¼ˆå¯ç”¨å¢å¼ºè¯„å®¡ï¼‰
    pipeline = DocumentCreationPipeline(
        pass_threshold=6,  # é™ä½é˜ˆå€¼ä¾¿äºæ¼”ç¤º
        max_iterations=3,
        enable_enhanced_review=True  # å¯ç”¨å¢å¼ºç‰ˆè¯„å®¡
    )
    
    # æµ‹è¯•ç”¨ä¾‹
    test_inputs = [
        "å¸®æˆ‘åˆ›å»ºä¸€ä¸ªæ–‡æ¡£å«'äº§å“ä»‹ç»'ï¼Œæ ‡é¢˜æ˜¯'æ–°å“å‘å¸ƒä¼š'ï¼Œå†…å®¹ä»‹ç»ä¸€ä¸‹æˆ‘ä»¬çš„AIåŠ©æ‰‹äº§å“",
        "å†™ä¸€ä»½å¹´åº¦æŠ¥å‘Šï¼Œè¦æ­£å¼ä¸€ç‚¹ï¼ŒåŒ…å«é”€å”®æ•°æ®è¡¨æ ¼",
        "åˆ›å»ºæ–‡æ¡£"  # ç¼ºå°‘å¿…è¦ä¿¡æ¯
    ]
    
    for i, user_input in enumerate(test_inputs, 1):
        print(f"\n\n{'#'*60}")
        print(f"# æµ‹è¯•ç”¨ä¾‹ {i}")
        print(f"# ç”¨æˆ·è¾“å…¥ï¼š{user_input}")
        print(f"{'#'*60}")
        
        result = pipeline.run(user_input, auto_confirm=True)
        
        print(f"\nğŸ“‹ ç»“æœæ‘˜è¦ï¼š")
        # åªæ‰“å°å…³é”®ä¿¡æ¯ï¼Œé¿å…è¾“å‡ºè¿‡é•¿
        summary = {
            "success": result.get("success"),
            "iterations": result.get("iterations"),
            "final_score": result.get("final_review", {}).get("score") if result.get("final_review") else None
        }
        print(json.dumps(summary, indent=2, ensure_ascii=False))
    
    # æ‰“å°æ”¹è¿›å»ºè®®æŠ¥å‘Š
    print("\n\n")
    print(pipeline.generate_improvement_report())


def demo_enhanced_review():
    """å•ç‹¬æ¼”ç¤ºå¢å¼ºç‰ˆè¯„å®¡åŠŸèƒ½"""
    
    print("=" * 60)
    print("ğŸ§ª å¢å¼ºç‰ˆ ReviewerAgent åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    task = StructuredTask(
        intent="create",
        document_name="test_doc.docx",
        title="AIæŠ€æœ¯ç™½çš®ä¹¦",
        content_requirements=[
            "ä»‹ç»äººå·¥æ™ºèƒ½çš„å‘å±•å†å²",
            "è¯´æ˜æœºå™¨å­¦ä¹ çš„åŸºæœ¬åŸç†",
            "æ¢è®¨AIåœ¨å„è¡Œä¸šçš„åº”ç”¨"
        ],
        style_requirements={"tone": "formal", "length": "long"},
        include_table=True
    )
    
    draft = DocumentDraft(
        filename="test_doc.docx",
        title="AIæŠ€æœ¯ç™½çš®ä¹¦",
        content="""# AIæŠ€æœ¯ç™½çš®ä¹¦

## å¼•è¨€

äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚

## å‘å±•å†å²

äººå·¥æ™ºèƒ½çš„å‘å±•å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®æ ‡å¿—ç€AIä½œä¸ºä¸€ä¸ªå­¦ç§‘çš„è¯ç”Ÿã€‚

## æœºå™¨å­¦ä¹ åŸºç¡€

æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ï¼Œè€Œæ— éœ€æ˜¾å¼ç¼–ç¨‹ã€‚

### ä¸»è¦ç±»å‹
- ç›‘ç£å­¦ä¹ 
- æ— ç›‘ç£å­¦ä¹ 
- å¼ºåŒ–å­¦ä¹ 

## è¡Œä¸šåº”ç”¨

AIå·²ç»åœ¨å¤šä¸ªé¢†åŸŸå¾—åˆ°å¹¿æ³›åº”ç”¨ï¼š
- åŒ»ç–—å¥åº·ï¼šç–¾ç—…è¯Šæ–­ã€è¯ç‰©ç ”å‘
- é‡‘èæœåŠ¡ï¼šé£é™©è¯„ä¼°ã€æ¬ºè¯ˆæ£€æµ‹
- åˆ¶é€ ä¸šï¼šè´¨é‡æ§åˆ¶ã€é¢„æµ‹æ€§ç»´æŠ¤
""",
        tables=[],
        images=[]
    )
    
    # åˆ›å»ºè¯„å®¡ Agent
    reviewer = ReviewerAgent(pass_threshold=7)
    
    # è¿›è¡Œå¢å¼ºç‰ˆè¯„å®¡
    print("\nğŸš€ å¼€å§‹å¢å¼ºç‰ˆè¯„å®¡...\n")
    result = reviewer.process_enhanced(draft, task, iteration=1)
    
    # æ‰“å°å®Œæ•´ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“‹ è¯„å®¡ç»“æœè¯¦æƒ…")
    print("=" * 60)
    
    print(f"\nâœ¨ æœ€ç»ˆè¯„åˆ†ï¼š{result.score}/10 ({'é€šè¿‡' if result.passed else 'æœªé€šè¿‡'})")
    print(f"ğŸ“ æ€»ä½“è¯„ä»·ï¼š{result.overall_feedback}")
    
    print("\nğŸ¯ CoT æ€è€ƒæ‘˜è¦ï¼š")
    print(f"  â€¢ ä»»åŠ¡æ€»ç»“ï¼š{result.cot_thinking.task_summary}")
    print(f"  â€¢ è‰ç¨¿æ€»ç»“ï¼š{result.cot_thinking.draft_summary}")
    print(f"  â€¢ æ„å›¾å¯¹é½ï¼š{result.cot_thinking.intent_alignment}")
    print(f"  â€¢ é£æ ¼ä¸€è‡´æ€§ï¼š{result.cot_thinking.style_consistency}")
    print(f"  â€¢ å¯¹é½å¾—åˆ†ï¼š{result.cot_thinking.alignment_score * 100:.1f}%")
    
    print("\nğŸ“Š å¤šç»´åº¦è¯„åˆ†ï¼š")
    for dim, score in [
        ("å†…å®¹è´¨é‡", result.dimension_scores.content_quality),
        ("ç»“æ„ç»„ç»‡", result.dimension_scores.structure_organization),
        ("è¯­è¨€è¡¨è¾¾", result.dimension_scores.language_expression),
        ("æ ¼å¼è§„èŒƒ", result.dimension_scores.format_standard),
        ("éœ€æ±‚åŒ¹é…", result.dimension_scores.requirement_match)
    ]:
        bar = "â–ˆ" * int(score) + "â–‘" * (10 - int(score))
        print(f"  {dim}ï¼š{bar} {score:.1f}")
    
    print("\nğŸ“¨ Agent åé¦ˆï¼š")
    for fb in result.agent_feedbacks:
        print(f"\n  [{fb.target_agent.upper()}]")
        print(f"    ä¼˜å…ˆçº§ï¼š{fb.priority}")
        print(f"    æ¶ˆæ¯ï¼š{fb.message}")
        if fb.action_items:
            print(f"    è¡ŒåŠ¨é¡¹ï¼š")
            for item in fb.action_items:
                print(f"      â€¢ {item}")
    
    return result


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "enhanced":
        demo_enhanced_review()
    else:
        demo()

